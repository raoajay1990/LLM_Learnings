{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c5750e-89f3-4ac0-8e50-d125b351b3ec",
   "metadata": {},
   "source": [
    "# Using Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "577b673b-c155-41e4-8a6d-1b0482c70a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tiktoken in c:\\users\\ajaye\\appdata\\roaming\\python\\python312\\site-packages (0.8.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\ajaye\\appdata\\roaming\\python\\python312\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\ajaye\\appdata\\roaming\\python\\python312\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ajaye\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ajaye\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ajaye\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ajaye\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Total number of characters : 20479\n",
      "5145\n",
      "x : [290, 4920, 2241, 287]\n",
      "y : [4920, 2241, 287, 257]\n",
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n",
      "[290] ----> 4920\n",
      " and ---->  established\n",
      "[290, 4920] ----> 2241\n",
      " and established ---->  himself\n",
      "[290, 4920, 2241] ----> 287\n",
      " and established himself ---->  in\n",
      "[290, 4920, 2241, 287] ----> 257\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "source": [
    "%run Input-targetPair.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2856050a-f67a-4161-9631-8bbb5e7fd613",
   "metadata": {},
   "source": [
    "# StepsÂ¶\n",
    "##### 1)Tokenize the entire text\n",
    "##### 2)use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "##### 3)Return the total number of rows in the dataset\n",
    "##### 4)Return a single row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f97d3c67-6fcc-4897-83f3-a0b59e12435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad08a017-0ada-4db1-bee6-f4dc07c99c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8e2b049-cdcc-4cf7-b986-bdd9eb25047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassDataSetV1(Dataset):
    "    def _init_(self,text, tokenizer, max_length, stride):\n",
    "        self.input_ids =[]\n",
    "        self.target_ids =[]\n",
    "        tokens_id = tokenizer.encode(text,allowed_special = {\"<|endoftext|>\"})\n",
    "\n",
    "        for i in range(0, len(token_id) - maxlength, stride):\n",
    "            input_chunk = token_id[i:i+maxlength]\n",
    "            target_chunk = token_id[i+1:i+maxlength+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
     
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4e6783-3632-4351-9e73-36425317fc3a",
   "metadata": {},
   "source": [
    "# DataLoader\n",
    "## Steps\n",
    "#### 1)Initialize the tokenizer\n",
    "#### 2)Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03299499-ccaf-4103-bc87-c77bed88d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(text, batch_size = 4,max_length = 256, stride = 128, shuffle = True, drop_last = True, num_workers = 0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = ClassDataSetV1(text, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = shuffle, drop_last = drop_last, num_workers = num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9d5bc83-0a58-46ed-9a5c-e7eb973b99fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('the-verdict.txt','r',encoding='utf-8') as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "454023e1-f8ae-4094-b71d-dd9f6d2d19ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size = 1, max_length = 4, stride = 1, shuffle = False)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb28f3-1ac4-448e-8429-eeff358e47b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
